from g4f.client import Client as G4FClient
from flask import Flask, request, jsonify
from flask_cors import CORS
from gradio_client import Client as GradioClient
import os
import base64
import random

# import sounddevice as sd
# import soundfile as sf
# import numpy as np
import threading
import queue
from kiwipiepy import Kiwi
from collections import Counter
from openai import OpenAI

app = Flask(__name__)
CORS(
    app,
    resources={
        r"/*": {"origins": ["http://localhost:5173", "http://127.0.0.1:5173", "*"]}
    },
)

client = G4FClient(api_key="not needed")  # g4f client
openai_client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
audio_queue = queue.Queue()
recording = False

# ë¨¼ì € ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í´ë¼ì´ì–¸íŠ¸
model_client = GradioClient("k2-fsa/text-to-speech")

# TTS ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë¼ì´ì–¸íŠ¸
tts_client = GradioClient("k2-fsa/text-to-speech")

# Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ì´ˆê¸°í™”
kiwi = Kiwi()


def translate_to_english(text):
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "You are a professional translator. Translate the given Korean text to natural English, maintaining the same meaning and nuance.",
                },
                {"role": "user", "content": f"Translate this to English: {text}"},
            ],
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"Translation error: {e}")
        return text


def load_questions_from_js():
    js_path = "../src/Questions.js"
    try:
        print("Attempting to load questions from:", js_path)  # íŒŒì¼ ê²½ë¡œ í™•ì¸
        with open(js_path, "r", encoding="utf-8") as file:
            content = file.read()
            print("File content length:", len(content))  # íŒŒì¼ ë‚´ìš© ë¡œë“œ í™•ì¸

            # ì„œë² ì´ ë¬¸ì œ ì¶”ì¶œ
            survey_start = content.find("'ì„œë² ì´': [")
            if survey_start == -1:  # ë¬¸ìì—´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
                print("Could not find 'ì„œë² ì´': [ in the file")
                return []

            survey_start += len("'ì„œë² ì´': [")
            survey_end = content.find("],", survey_start)
            if survey_end == -1:  # ë ë¶€ë¶„ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°
                print("Could not find ending ], for survey questions")
                return []

            survey_str = content[survey_start:survey_end].strip()
            print(
                "Extracted survey string length:", len(survey_str)
            )  # ì¶”ì¶œëœ ë¬¸ìì—´ í™•ì¸

            # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            questions = []
            current_question = ""
            in_quote = False

            for char in survey_str:
                if char in ['"', "'"]:
                    in_quote = not in_quote
                elif char == "," and not in_quote:
                    if current_question.strip():
                        questions.append(current_question.strip().strip('"').strip("'"))
                    current_question = ""
                else:
                    current_question += char

            if current_question.strip():
                questions.append(current_question.strip().strip('"').strip("'"))

            print("Number of questions loaded:", len(questions))  # ìµœì¢… ë¬¸ì œ ìˆ˜ í™•ì¸
            print("First few questions:", questions[:3])  # ì²« ëª‡ ê°œ ë¬¸ì œ í™•ì¸
            return questions
    except Exception as e:
        print(f"Error loading questions: {e}")
        return []


def audio_callback(indata, frames, time, status):
    if recording:
        audio_queue.put(indata.copy())


# def record_audio():
#     with sd.InputStream(callback=audio_callback, channels=1, samplerate=16000):
#         while recording:
#             sd.sleep(100)


@app.route("/analyze-text", methods=["POST"])
def analyze_text():
    data = request.json
    text = data.get("text", "")

    if not text:
        return jsonify({"error": "No text provided"}), 400

    # í˜•íƒœì†Œ ë¶„ì„ ë° í’ˆì‚¬ íƒœê¹…
    pos_list = kiwi.analyze(text)[0][0]  # ì²« ë²ˆì§¸ ë¶„ì„ ê²°ê³¼ì˜ í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼

    # í’ˆì‚¬ë³„ ë‹¨ì–´ ì¹´ìš´íŒ…
    word_count_by_pos = {}
    for token in pos_list:
        pos = token.tag  # í’ˆì‚¬
        word = token.form  # ë‹¨ì–´

        if pos not in word_count_by_pos:
            word_count_by_pos[pos] = Counter()
        word_count_by_pos[pos][word] += 1

    # ê° í’ˆì‚¬ë³„ ìƒìœ„ ë‹¨ì–´ ì¶”ì¶œ
    result_by_pos = {}
    for pos, counter in word_count_by_pos.items():
        result_by_pos[pos] = counter.most_common(10)  # ìƒìœ„ 10ê°œ ë‹¨ì–´

    return jsonify(
        {
            "total_words": len(pos_list),
            "unique_words": len(set(token.form for token in pos_list)),
            "word_count_by_pos": result_by_pos,
        }
    )


@app.route("/generate-sentences", methods=["POST"])
def generate_sentences():
    try:
        data = request.json
        analysis = data.get("analysis", {})

        # ë¶„ì„ ë°ì´í„°ì—ì„œ ì£¼ìš” ë‹¨ì–´ ì¶”ì¶œ
        nouns = [
            word for word, _ in analysis.get("word_count_by_pos", {}).get("NNG", [])
        ]
        verbs = [
            word for word, _ in analysis.get("word_count_by_pos", {}).get("VV", [])
        ]
        adverbs = [
            word for word, _ in analysis.get("word_count_by_pos", {}).get("MAG", [])
        ]

        # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""You are an expert OPIC tutor specializing in creating "Universal Sentences (ë§ŒëŠ¥ë¬¸ì¥)".

        Based on these frequently used Korean words from the student:
        Nouns: {', '.join(nouns[:5])}
        Verbs: {', '.join(verbs[:5])}
        Adverbs: {', '.join(adverbs[:5])}

        Create 10 pairs of OPIC universal sentences (ë§ŒëŠ¥ë¬¸ì¥) that meet these criteria:

        Key Requirements:
        1. REUSABILITY (ì¬í™œìš©ì„±)
        - Can be adapted to various similar situations
        - Easy to modify by changing key words
        - Flexible enough to use in multiple OPIC topics

        2. NATURALNESS (ìì—°ìŠ¤ëŸ¬ì›€)
        - Must use casual, spoken Korean (êµ¬ì–´ì²´) like '-ìš”', '-ê±°ë“ ìš”', '-ëŠ”ë°ìš”' endings
        - Avoid formal or written language patterns
        - Use everyday conversational expressions and fillers
        - Sound like natural daily conversation, as if talking to a friend
        - Use declarative sentences, NOT questions
        - Include common spoken expressions like 'ê·¸ë˜ì„œ', 'ì‚¬ì‹¤ì€', 'ì§„ì§œ' etc.

        3. EFFECTIVENESS (íš¨ê³¼ì„±)
        - Incorporate the student's frequently used words
        - Simple yet sophisticated enough for OPIC
        - Include useful expressions for scoring points
        - Focus on casual, spoken statements and descriptions

        4. PRACTICALITY (ì‹¤ìš©ì„±)
        - Easy to memorize and use
        - Relevant to daily life experiences
        - Can be used as template sentences
        - Should be conversational declarative sentences that describe situations or express opinions
        - Must sound natural in spoken Korean

        Format each sentence pair as:
        {{
            "korean": "êµ¬ì–´ì²´ í•œêµ­ì–´ ë§ŒëŠ¥ë¬¸ì¥ (ì˜ˆ: ~ëŠ”ë°ìš”, ~ê±°ë“ ìš”, ~ìš” ë“±ì˜ ë§íˆ¬)",
            "english": "Natural conversational English (casual speaking style)",
            "usage": "When and how to use this sentence (ì‚¬ìš© ìƒí™© ì„¤ëª…)"
        }}

        Return only the JSON array of 10 sentence pairs, focusing on creating truly reusable, natural, and effective universal sentences that reflect authentic spoken Korean."""

        # GPTë¡œ ë¬¸ì¥ ìƒì„±
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": """You are an OPIC tutor who specializes in creating 'ë§ŒëŠ¥ë¬¸ì¥' (universal sentences).
                    ë§ŒëŠ¥ë¬¸ì¥ are special sentences that:
                    - Are easy to remember
                    - Can be used in multiple situations
                    - Sound natural in conversation
                    - Help score higher on OPIC tests
                    Your goal is to create sentences that students can easily adapt and reuse.""",
                },
                {"role": "user", "content": prompt},
            ],
        )

        return jsonify(
            {
                "sentences": response.choices[0].message.content,
                "words": {
                    "nouns": nouns[:5],
                    "verbs": verbs[:5],
                    "adverbs": adverbs[:5],
                },
            }
        )

    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/generate-audio", methods=["POST"])
def generate_audio():
    try:
        data = request.json
        text = data.get("text")

        if not text:
            raise ValueError("Text is required")

        print(f"Generating audio for text: {text}")

        # TTS ìƒì„±
        result = tts_client.predict(
            "English",  # language
            "csukuangfj/kokoro-en-v0_19|11 speakers",  # repo_id
            text,  # text
            "0",  # sid
            1.0,  # speed
            api_name="/process",
        )

        print("Raw TTS result:", result)  # ì‹¤ì œ ê²°ê³¼ê°’ í™•ì¸

        # ê²°ê³¼ê°€ íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°, íŒŒì¼ì„ ì½ì–´ì„œ ì§ì ‘ ì „ì†¡
        if isinstance(result, (tuple, list)):
            audio_path = result[0]
        else:
            audio_path = result

        print("Audio path:", audio_path)

        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"Audio file not found at {audio_path}")

        # íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ë¡œ ì½ì–´ì„œ base64ë¡œ ì¸ì½”ë”©
        with open(audio_path, "rb") as audio_file:
            audio_data = base64.b64encode(audio_file.read()).decode("utf-8")

        return jsonify({"audio_data": audio_data, "content_type": "audio/wav"})

    except Exception as e:
        print(f"Detailed error in generate_audio: {str(e)}")
        return jsonify({"error": str(e)}), 500


# ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ ê´€ë ¨ ë¼ìš°íŠ¸ë“¤
@app.route("/get-test-questions", methods=["GET"])
def get_questions():
    try:
        # Questions.jsì—ì„œ ë¬¸ì œ ë¡œë“œ
        all_questions = load_questions_from_js()
        print("Total questions loaded:", len(all_questions))  # ë¡œë“œëœ ì „ì²´ ë¬¸ì œ ìˆ˜

        if not all_questions:
            print("No questions were loaded!")
            return jsonify({"error": "No questions available"}), 500

        # ëœë¤í•˜ê²Œ 4ê°œ ì„ íƒ
        selected_questions = random.sample(all_questions, min(4, len(all_questions)))
        print("Selected questions:", selected_questions)  # ì„ íƒëœ ë¬¸ì œë“¤

        # ê° ë¬¸ì œì— ëŒ€í•´ ì˜ì–´ ë²ˆì—­ ìˆ˜í–‰
        questions = []
        for q in selected_questions:
            translated = translate_to_english(q)
            print(f"Original: {q}")  # ì›ë³¸ ë¬¸ì œ
            print(f"Translated: {translated}")  # ë²ˆì—­ëœ ë¬¸ì œ
            questions.append({"korean": q, "english": translated})

        return jsonify(questions)
    except Exception as e:
        print(f"Error in get_questions: {e}")
        return jsonify({"error": str(e)}), 500


# @app.route("/start-recording", methods=["POST"])
# def start_recording():
#     global recording
#     recording = True
#     threading.Thread(target=record_audio).start()
#     return jsonify({"status": "recording started"})


# @app.route("/stop-recording", methods=["POST"])
# def stop_recording():
#     global recording
#     recording = False

#     audio_data = []
#     while not audio_queue.empty():
#         audio_data.append(audio_queue.get())

#     audio_data = np.concatenate(audio_data)
#     sf.write("temp.wav", audio_data, 16000)

#     # OpenAI API ì‚¬ìš© ì½”ë“œ
#     with open("temp.wav", "rb") as audio_file:
#         result = openai_client.audio.transcriptions.create(
#             model="whisper-1", file=audio_file
#         )

#     return jsonify({"transcription": result.text})


@app.route("/get-feedback", methods=["POST"])
def get_feedback():
    answers = request.json.get("answers")
    feedback = {}

    for idx, answer in answers.items():
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": """ë‹¹ì‹ ì€ OPIC ì „ë¬¸ ì±„ì ê´€ì…ë‹ˆë‹¤. 
                ë‹¤ìŒ OPIC ì±„ì  ê¸°ì¤€ì— ë”°ë¼ í•™ìƒì˜ ë‹µë³€ì„ í‰ê°€í•˜ê³ , ì¹œê·¼í•˜ê³  ëª…í™•í•œ í•œêµ­ì–´ë¡œ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”.

                â–  í‰ê°€ ê¸°ì¤€:
                1. ìƒí™©ëŒ€ì²˜ëŠ¥ë ¥
                   - ì£¼ì–´ì§„ ìƒí™©ê³¼ ì§ˆë¬¸ì— ë§ëŠ” ì ì ˆí•œ ë‹µë³€
                   - ì˜ì–´ ìœ ì°½í•¨ê³¼ ìì‹ ê°
                
                2. ì˜ì–´ ìŠ¤íƒ€ì¼
                   - ë°œìŒ, ì–µì–‘, í‘œí˜„ë°©ì‹
                   - ìì—°ìŠ¤ëŸ¬ìš´ ì˜ì–´ êµ¬ì‚¬ë ¥
                
                3. ë¬¸ë²•
                   - ì‹œì œ, ìˆ˜ì¼ì¹˜ ë“± ê¸°ë³¸ ë¬¸ë²•
                   - ë‹µë³€ ë‚´ìš©ì˜ ë¬¸ë²•ì  ì •í™•ì„±
                
                4. ë‹µë³€êµ¬ì¡°
                   - ì„œë¡ -ë³¸ë¡ -ê²°ë¡ ì˜ ëª…í™•í•œ êµ¬ì„±
                   - ë‹µë³€ ë‚´ìš©ì˜ ì²´ê³„ì  ì „ê°œ

                â–  í”¼ë“œë°± í˜•ì‹:

                ğŸ“Œ ì¢…í•© í‰ê°€
                [ë‹µë³€ì˜ ì „ë°˜ì ì¸ ê°•ì ê³¼ ì¸ìƒì ì¸ ë¶€ë¶„ì„ 2-3ì¤„ë¡œ ìš”ì•½]

                ğŸ’ª ì˜í•œ ì 
                â€¢ [êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì˜í•œ ì  ë‚˜ì—´]
                â€¢ [ì‹¤ì œ ë‹µë³€ì—ì„œ ì‚¬ìš©í•œ ì¢‹ì€ í‘œí˜„ ì¸ìš©]
                
                ğŸ“ ê°œì„ í•  ì 
                â€¢ [ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…]
                â€¢ [ì‹¤ì œ êµì • ì˜ˆì‹œ ì œì‹œ]

                ğŸ’¡ í•™ìŠµ ì¡°ì–¸
                â€¢ [ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í•™ìŠµ ë°©ë²• ì œì‹œ]
                â€¢ [ë‹¤ìŒ ë‹µë³€ì„ ìœ„í•œ í•µì‹¬ í‘œí˜„ ì¶”ì²œ]

                ì£¼ì˜ì‚¬í•­:
                - ì¹œê·¼í•˜ê³  ê²©ë ¤í•˜ëŠ” í†¤ ìœ ì§€
                - êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…
                - ì¤‘ìš”í•œ ì˜ì–´ í‘œí˜„ì€ ê´„í˜¸ ì•ˆì— ë³‘ê¸°
                - ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸ ì œì‹œ
                """,
                },
                {"role": "user", "content": f"ë‹¤ìŒ OPIC ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”: {answer}"},
            ],
        )
        feedback[idx] = response.choices[0].message.content

    return jsonify({"feedback": feedback})


@app.route("/transcribe", methods=["POST"])
def transcribe_audio():
    try:
        if "file" not in request.files:
            return jsonify({"error": "No file part"}), 400

        file = request.files["file"]
        file.save("temp.wav")

        with open("temp.wav", "rb") as audio_file:
            result = openai_client.audio.transcriptions.create(
                model="whisper-1", file=audio_file
            )

        return jsonify({"transcription": result.text})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


if __name__ == "__main__":
    app.run(debug=True, port=5001)
